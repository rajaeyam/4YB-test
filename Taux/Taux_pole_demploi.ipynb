{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsgj84guthGe"
   },
   "source": [
    "# BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN8f1wmKrq2M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "n=100000\n",
    "def salaire_brut_mensuel(statut):\n",
    "    # Dictionnaire contenant les marges de salaire selon le statut\n",
    "    marges_salaire = {\n",
    "        \"Admi / Tech art 36\": (1414.37, 3279.44),\n",
    "        \"Employé\": (945.96, 3744.35),\n",
    "        \"Agent de maitrise\": (2545.20, 4247.14),\n",
    "        \"Cadre\": (2496.48, 8896.26),\n",
    "        \"Cadre DNR\": (7155.24, 7155.24),\n",
    "        \"Collaborateur 4/4bis\": (4006.41, 6112.24),\n",
    "        \"Ouvrier\": (1326.81, 3890.00),\n",
    "        \"Executive\": (7400.00, 9980.00),\n",
    "        \"Apprenti (B.C)\": (1413.54, 1413.54),\n",
    "        \"Apprenti (W.C)\": (1077.82, 1766.92),\n",
    "        \"Stagiaire\": (600, 1500),\n",
    "        \"Contrat pro (Cadre)\":(1077.82, 1766.92),\n",
    "        \"Admi / Tech\":(1077.82, 1766.92),\n",
    "    }\n",
    "\n",
    "    # Vérifier si le statut est valide\n",
    "    if statut in marges_salaire:\n",
    "        min_salaire, max_salaire = marges_salaire[statut]\n",
    "        if min_salaire == max_salaire:\n",
    "            return min_salaire\n",
    "        else:\n",
    "            \n",
    "            return round(random.uniform(min_salaire, max_salaire), 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Statut non reconnu: {statut}\")\n",
    "\n",
    "frontalier = ['Frontaliers', 'Non']\n",
    "Region = ['Moselle', 'Autre']\n",
    "\n",
    "statuts_exoneres = ['Stagiaire', 'Apprenti (B.C)', 'Apprenti (W.C)', 'Mandat Social']\n",
    "\n",
    "def generate_numero_serie():\n",
    "    return ''.join([str(random.randint(0, 9)) for _ in range(14)])\n",
    "\n",
    "\n",
    "# Paramètres du SMIC pour le calcul du plafond\n",
    "smic_horaire = 11.65\n",
    "heures_par_jour = 7\n",
    "smic_horaire_taux_specifique = 11.65  # SMIC horaire pour le calcul des taux spécifiques\n",
    "heures_hebdomadaires = 35\n",
    "heures_mensuelles = (35 * 52) / 12\n",
    "plafond_coef = 2.5\n",
    "semaines_par_an = 52\n",
    "jours_legal_mois = 23\n",
    "\n",
    "# Définir les constantes pour CSG-CRDS\n",
    "PLAFOND_ANNUEL_SS = 46368\n",
    "PLAFOND_MENSUEL_SS = 3864\n",
    "\n",
    "\n",
    "ABATTEMENT = 0.0175\n",
    "# 'Contrat pro (Cadre)','Admi / Tech'\n",
    "statut_emp = ['Employé' ,'Collaborateur 4/4bis' ,'Admi / Tech art 36', 'Cadre' ,'Cadre DNR' ,'Executive' ,'Apprenti (B.C)', 'Apprenti (W.C)','Ouvrier', 'Agent de maitrise','Stagiaire']\n",
    "type_contrat_ = ['CDI Standard', 'CDD standard','CDD Ctr pro','CDD Doctorant','Apprenti','Mandat Social','Stagiaire']\n",
    "Catégorie_texte = ['Employé', 'Expatrié']\n",
    "Societe = ['Anoflexe','Tiers' ,'Continental France' ,'Contitech France','Continental Digital Services France']\n",
    "\n",
    "\n",
    "def determiner_taux_pole_demploi(tranche_a,tranche_b):\n",
    "  \"\"\"Calcul du taux pole_demploi \"\"\"\n",
    "  if   tranche_a == 0.0 :\n",
    "    taux_7C00 = 0.0\n",
    "  else :\n",
    "    taux_7C00 = 4.05\n",
    "  if   tranche_b == 0.0 :\n",
    "    taux_7C10 = 0.0\n",
    "  else :\n",
    "    taux_7C10 = 4.05\n",
    "\n",
    "\n",
    "  return taux_7C00,taux_7C10\n",
    "\n",
    "\n",
    "def calculate_base_pole_demploi(brut_cum,plafond_cum,cum_base_tranche_a_prec,cum_base_tranche_b_prec,type_contrat):\n",
    "  \"\"\"Calcul de la base pole_demploi \"\"\"\n",
    "  if  type_contrat != 'Mandat Social' and type_contrat !='Stagiaire' and type_contrat !='Apprenti'  :\n",
    "\n",
    "    if brut_cum < plafond_cum:\n",
    "      tranche_a = brut_cum - cum_base_tranche_a_prec -cum_base_tranche_b_prec\n",
    "      if cum_base_tranche_b_prec !=0:\n",
    "        tranche_b = -cum_base_tranche_b_prec\n",
    "      else : tranche_b =0\n",
    "    else:\n",
    "      tranche_a = plafond_cum - cum_base_tranche_a_prec\n",
    "      if brut_cum > 4* plafond_cum:\n",
    "        tranche_b = 4*plafond_cum -cum_base_tranche_a_prec -cum_base_tranche_b_prec\n",
    "      else :\n",
    "        tranche_b = brut_cum -cum_base_tranche_a_prec- cum_base_tranche_b_prec\n",
    "\n",
    "  else :\n",
    "    tranche_a = 0.0\n",
    "    tranche_b = 0.0\n",
    "\n",
    "\n",
    "  return round(tranche_a, 2),round(tranche_b, 2)\n",
    "def calculate_base_AGS(brut_cum, plafond_cum, cum_base_tranche_a_prec, cum_base_tranche_b_prec, type_contrat):\n",
    "    # print(f\"Inputs: brut_cum={brut_cum}, plafond_cum={plafond_cum}, cum_base_tranche_a_prec={cum_base_tranche_a_prec}, cum_base_tranche_b_prec={cum_base_tranche_b_prec}, type_contrat={type_contrat}\")\n",
    "\n",
    "    if type_contrat not in ['Mandat Social', 'Stagiaire']:\n",
    "        # Initialisation des variables\n",
    "        tranche_a = 0.0\n",
    "        tranche_b = 0.0\n",
    "        # print(\"Calcul pour un contrat standard\")\n",
    "\n",
    "        # Cas où le brut cumulé est inférieur au plafond\n",
    "        if brut_cum < plafond_cum:\n",
    "            tranche_a = brut_cum - cum_base_tranche_a_prec - cum_base_tranche_b_prec\n",
    "            # print(f\"tranche_a calculée: {tranche_a}\")\n",
    "            tranche_b = -cum_base_tranche_b_prec if cum_base_tranche_b_prec != 0 else 0.0\n",
    "            # print(f\"tranche_b calculée: {tranche_b}\")\n",
    "        else:  # Cas où le brut cumulé est supérieur ou égal au plafond\n",
    "            tranche_a = plafond_cum - cum_base_tranche_a_prec\n",
    "            # print(f\"tranche_a calculée: {tranche_a}\")\n",
    "            if brut_cum > 4 * plafond_cum:\n",
    "                tranche_b = 4 * plafond_cum - cum_base_tranche_a_prec - cum_base_tranche_b_prec\n",
    "            else:\n",
    "                tranche_b = brut_cum - cum_base_tranche_a_prec - cum_base_tranche_b_prec\n",
    "            # print(f\"tranche_b calculée: {tranche_b}\")\n",
    "\n",
    "        # Calcul de la base AGS\n",
    "        ags_base = tranche_a + tranche_b\n",
    "        # print(f\"ags_base calculée: {ags_base}\")\n",
    "    else:  # Cas des contrats \"Mandat Social\" ou \"Stagiaire\"\n",
    "        # print(\"Contrat non éligible\")\n",
    "        tranche_a = 0.0\n",
    "        tranche_b = 0.0\n",
    "        ags_base = 0.0\n",
    "\n",
    "    # Retourner la valeur arrondie\n",
    "    ags_base = round(ags_base, 2)\n",
    "    # print(f\"Resultat final: {ags_base}\")\n",
    "    return ags_base\n",
    "\n",
    "\n",
    "\n",
    "def determiner_taux_ags(ags_base):\n",
    "   \"\"\"Calcul de la base ags \"\"\"\n",
    "   if ags_base == 0.0    :\n",
    "    taux_ags = 0.0\n",
    "   else :\n",
    "    taux_ags = 0.25\n",
    "   return taux_ags\n",
    "\n",
    "# Function to calculate the adjusted social security ceiling based on absence days and extra hours\n",
    "def calculer_plafond_sec_social(jours_absence):\n",
    "    return PLAFOND_MENSUEL_SS * (jours_travailles_mois / 30)\n",
    "\n",
    "\n",
    "# Générer les données pour plusieurs mois\n",
    "np.random.seed(42)\n",
    "data = []\n",
    "cumuls_employes = {}\n",
    "nombre_mois_simules = 12\n",
    "effectif = np.random.randint(1, 49, n)  # Effectif aléatoire entre 1 et 99\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    Numero_serie = generate_numero_serie()\n",
    "    # Utiliser la fonction salaire_brut_mensuel pour définir le brut_mensuel\n",
    "    statut = np.random.choice(statut_emp)\n",
    "    type_contrat = np.random.choice(type_contrat_)\n",
    "    brut_mensuel= salaire_brut_mensuel(statut)\n",
    "    remuneration_annuelle = round(brut_mensuel * 12, 2)\n",
    "    #residence = np.random.choice(Catégorie_texte)\n",
    "    frontaliers = np.random.choice(frontalier)\n",
    "    regions = np.random.choice(Region)\n",
    "\n",
    "    # Initialiser les cumuls pour chaque employé\n",
    "    if Numero_serie not in cumuls_employes:\n",
    "        cumuls_employes[Numero_serie] = {\n",
    "\n",
    "           'sum_remunerations': [0] * nombre_mois_simules,\n",
    "            'sum_smic': [0] * nombre_mois_simules,\n",
    "            'sum_assiette_plafonnee': [0] * nombre_mois_simules,\n",
    "            'sum_pass_ajusted':[0] * nombre_mois_simules,\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    # Générer une date d'embauche aléatoire en 2024 avant la date de paie\n",
    "    date_embauche_jour = np.random.randint(1, 31)\n",
    "    date_embauche_mois = np.random.randint(1, 13)\n",
    "    while date_embauche_mois > nombre_mois_simules:\n",
    "        date_embauche_mois = np.random.randint(1, 13)\n",
    "\n",
    "\n",
    "\n",
    "    cum_base_tranche_a_prec_m1 = 0\n",
    "    cum_base_tranche_b_prec_m1 = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for mois in range(date_embauche_mois, nombre_mois_simules + 1):\n",
    "        date_paie = f\"2024-{mois:02d}-01\"  # Date fictive pour le bulletin de paie\n",
    "\n",
    "        # Gestion des absences et des heures sups pour chaque mois\n",
    "        jours_absence = np.random.randint(0, 4)  # Jours d'absence entre 0 et 10\n",
    "        heures_absence = jours_absence * heures_par_jour\n",
    "        heures_supplementaires = np.random.randint(0, 12)\n",
    "\n",
    "        jours_travailles_mois = 30 - date_embauche_jour + 1 - jours_absence\n",
    "        salaire_absence = round(brut_mensuel * (heures_absence / heures_mensuelles), 2)\n",
    "        brut_mensuel_apres_absence = round(brut_mensuel - salaire_absence, 2)\n",
    "        plafond_adjusted = calculer_plafond_sec_social(jours_absence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calcul du SMIC mensuel\n",
    "        smic_mensuel = round((heures_hebdomadaires * semaines_par_an / 12) * smic_horaire_taux_specifique, 2)\n",
    "\n",
    "        # Calcul du SMIC de référence\n",
    "        smic_reference = round(smic_mensuel * (brut_mensuel_apres_absence / brut_mensuel)  + (heures_supplementaires * smic_horaire), 2)\n",
    "\n",
    "        plafond_mensuel_reference = round(plafond_coef * smic_reference, 2)\n",
    "\n",
    "        # Mise à jour des valeurs cumulées de manière synthétique\n",
    "        if mois > date_embauche_mois:\n",
    "            cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1] = cumuls_employes[Numero_serie]['sum_remunerations'][mois - 2] + brut_mensuel_apres_absence\n",
    "            cumuls_employes[Numero_serie]['sum_smic'][mois - 1] = cumuls_employes[Numero_serie]['sum_smic'][mois - 2] + smic_reference\n",
    "            cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 1] = cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 2] + plafond_adjusted\n",
    "        else:\n",
    "            cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1] = brut_mensuel_apres_absence\n",
    "            cumuls_employes[Numero_serie]['sum_smic'][mois - 1] = smic_reference\n",
    "\n",
    "            cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 1] = plafond_adjusted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        brut_cum = cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1]\n",
    "        pass_cum = cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 1]\n",
    "\n",
    "        # Calcul des cotisations\n",
    "        if mois > date_embauche_mois:\n",
    "            sum_remunerations_mois = cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1]\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            sum_remunerations_mois = cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        base_tranche_a, base_tranche_b= calculate_base_pole_demploi(brut_cum,pass_cum,cum_base_tranche_a_prec_m1,cum_base_tranche_b_prec_m1,type_contrat,)\n",
    "        taux_7C00,taux_7C10 = determiner_taux_pole_demploi(base_tranche_a,base_tranche_b)\n",
    "        montant_tranche_a = base_tranche_a * taux_7C00 /100\n",
    "        montant_tranche_b = base_tranche_b * taux_7C00 /100\n",
    "\n",
    "\n",
    "        # AGS\n",
    "\n",
    "        base_ags= calculate_base_AGS(brut_cum,pass_cum,cum_base_tranche_a_prec_m1,cum_base_tranche_b_prec_m1,type_contrat)\n",
    "        taux_ags = determiner_taux_ags(base_ags)\n",
    "        montant_7C20 = taux_ags * base_ags/100\n",
    "\n",
    "        cum_base_tranche_a_prec_m2 = cum_base_tranche_a_prec_m1\n",
    "        cum_base_tranche_a_prec_m1 += base_tranche_a\n",
    "\n",
    "        cum_base_tranche_b_prec_m2 = cum_base_tranche_b_prec_m1\n",
    "        cum_base_tranche_b_prec_m1 += base_tranche_b\n",
    "\n",
    "        # Ajout des données au dataframe\n",
    "        data.append({\n",
    "            'Matricule': Numero_serie,\n",
    "            'Statut de salariés': statut,\n",
    "            'date de paie' : date_paie,\n",
    "            'date embauche jour' : date_embauche_jour,\n",
    "            'date embauche mois' : date_embauche_mois,\n",
    "            'Effectif': effectif[i],\n",
    "            'Statut de salariés': statut,\n",
    "            'Type de contrat' : type_contrat,\n",
    "            '1001 Montant Sal.': brut_mensuel,\n",
    "            'Absences par Jour': jours_absence,\n",
    "            'ABATTEMENT' : ABATTEMENT ,\n",
    "            'Assiette Mois M (/102)' :  round(brut_mensuel_apres_absence,2),\n",
    "            'Absences par Heure':heures_absence,\n",
    "            'PLAFOND CUM' : cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 1],\n",
    "\n",
    "            # 'PLAFOND CUM Precedent' : round(cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 2],2),\n",
    "            'PLAFOND CUM M-1' : cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 2],\n",
    "            '4*PLAFOND' : 4* cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 1],\n",
    "            '4*PLAFOND CUM Precedent' : 4*cumuls_employes[Numero_serie]['sum_pass_ajusted'][mois - 2],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \"Cumul d'assiette ( Mois courant inclus) (/102)\":cumuls_employes[Numero_serie]['sum_remunerations'][mois - 1],\n",
    "            'ASSIETTE CUM PRECEDENTE':cumuls_employes[Numero_serie]['sum_remunerations'][mois - 2],\n",
    "            'Rub 7C20' : '7C20',\n",
    "            '7C20Base' : base_ags ,\n",
    "            '7C20Taux 2' : taux_ags,\n",
    "            '7C20Montant Pat.' : montant_7C20,\n",
    "\n",
    "\n",
    "# base_tranche_a, base_tranche_b, taux_7C00,montant_tranche_a\n",
    "            'Rub 7C00' : '7C00',\n",
    "            '7C00Base' : base_tranche_a ,\n",
    "            'Cum base 7C00' : cum_base_tranche_a_prec_m2,\n",
    "            '7C00Taux 2' : taux_7C00,\n",
    "            '7C00Montant Pat.' : montant_tranche_a,\n",
    "\n",
    "            'Rub 7C10' : '7C10',\n",
    "            '7C10Base' : base_tranche_b ,\n",
    "            'Cum base 7C10' : cum_base_tranche_b_prec_m2,\n",
    "            '7C10Taux 2' : taux_7C10,\n",
    "            '7C10Montant Pat.' : montant_tranche_b,\n",
    "\n",
    "            'Frontalier':frontaliers,\n",
    "            'Region' : regions\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df.round(3)\n",
    "\n",
    "print(df.head())\n",
    "len(df)\n",
    "\n",
    "# #supprimer les valeurs negatifs\n",
    "# # Sélectionner les colonnes numériques\n",
    "# numeric_df = df.select_dtypes(include=[np.number])\n",
    "# # Identifier les lignes sans valeurs négatives\n",
    "# rows_to_keep = ~(numeric_df < 0).any(axis=1)\n",
    "# # Filtrer le DataFrame original pour ne garder que les lignes sans valeurs négatives\n",
    "# df_cleaned = df[rows_to_keep]\n",
    "# # Sauvegarder la base de données résultante en CSV\n",
    "df.to_csv('pole.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNsY-xYqIcr3"
   },
   "source": [
    "# 7C20Taux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY1Sjy5J4ls3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"pole.csv\")\n",
    "\n",
    "percentage = 0.18\n",
    "def generer_taux_errone_maladie(eliminer_valeur=None):\n",
    "\n",
    "    taux_errone = round(np.random.uniform(0, 10), 2)  \n",
    "    while eliminer_valeur is not None and taux_errone == eliminer_valeur:\n",
    "        taux_errone = round(np.random.uniform(0, 10), 2)  \n",
    "    return taux_errone\n",
    "\n",
    "maladie_rows = df.sample(frac=percentage).index\n",
    "df['7C20 Fraud'] = 0\n",
    "for idx in maladie_rows:\n",
    "    if df.at[idx, '7C20Taux 2'] == 0.0:\n",
    "        df.at[idx, '7C20Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=0.0)\n",
    "        df.at[idx, '7C20 Fraud'] = 1\n",
    "    elif df.at[idx, '7C20Taux 2'] == 0.25:\n",
    "        df.at[idx, '7C20Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=0.25)\n",
    "        df.at[idx, '7C20 Fraud'] = 1\n",
    "    # elif df.at[idx, '7C20Base'] != 0.0:\n",
    "    #     df.at[idx, '7C20Taux 2'] == 0\n",
    "    #     df.at[idx, '7C20 Fraud'] = 1\n",
    "\n",
    "df.to_csv(\"7C20_avec_anomalies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dpfdl48zuqmO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv('7C20_avec_anomalies.csv')\n",
    "features = df[[ 'Type de contrat','7C20Base' ,'7C20Taux 2']]\n",
    "\n",
    "features_encoded = pd.get_dummies(features, columns=['Type de contrat'], drop_first=True)\n",
    "\n",
    "\n",
    "target = df['7C20 Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxL5h2KH7JIC"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_classifier, '7C20_new_model_random_forest.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CWMLzw47SNv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "rf_classifier_loaded = joblib.load('7C20_new_model_random_forest.pkl')\n",
    "\n",
    "new_df = pd.read_csv('/content/test7c20 - pole (2).csv (3).csv')\n",
    "df['7C20Taux 2'] = df['7C20Taux 2'].fillna(0)\n",
    "df['7C20Base'] = df['7C20Base'].fillna(0)\n",
    "\n",
    "features_new = new_df[[ 'Type de contrat','7C20Base' ,'7C20Taux 2']]\n",
    "\n",
    "features_new_encoded = pd.get_dummies(features_new, columns=['Type de contrat'], drop_first=True)\n",
    "\n",
    "missing_cols = set(features_encoded.columns) - set(features_new_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    features_new_encoded[c] = 0\n",
    "\n",
    "features_new_encoded = features_new_encoded[features_encoded.columns]\n",
    "\n",
    "predictions = rf_classifier_loaded.predict(features_new_encoded)\n",
    "\n",
    "new_df['anomalie_predite'] = predictions\n",
    "\n",
    "# Sauvegarder la nouvelle base avec les prédictions\n",
    "#new_df.to_csv('nouvelle_base_avec_predictions.csv', index=False)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1JJKL6MImpn"
   },
   "source": [
    "# 7C00 Taux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Q9846GBIip_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"pole.csv\")\n",
    "\n",
    "\n",
    "percentage = 0.20\n",
    "def generer_taux_errone_maladie(eliminer_valeur=None):\n",
    "\n",
    "    taux_errone = round(np.random.uniform(0, 10), 2) \n",
    "    while eliminer_valeur is not None and taux_errone == eliminer_valeur:\n",
    "        taux_errone = round(np.random.uniform(0, 10), 2)  \n",
    "    return taux_errone\n",
    "\n",
    "\n",
    "maladie_rows = df.sample(frac=percentage).index\n",
    "df['7C00 Fraud'] = 0\n",
    "for idx in maladie_rows:\n",
    "    if df.at[idx, '7C00Taux 2'] == 0.0:\n",
    "        df.at[idx, '7C00Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=0.0)\n",
    "        df.at[idx, '7C00 Fraud'] = 1\n",
    "    elif df.at[idx, '7C00Taux 2'] == 4.05:\n",
    "        df.at[idx, '7C00Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=4.05)\n",
    "        df.at[idx, '7C00 Fraud'] = 1\n",
    "    # elif df.at[idx, '7C00Base'] == 0.0:\n",
    "    #     df.at[idx, '7C00Taux 2'] = round(np.random.uniform(1, 10), 2)\n",
    "    #     df.at[idx, '7C00 Fraud'] = 1\n",
    "\n",
    "\n",
    "df.to_csv(\"7C00_avec_anomalies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-vrV6MpH5Mo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv('7C00_avec_anomalies.csv')\n",
    "\n",
    "features = df[['7C00Base', '7C00Taux 2']]\n",
    "\n",
    "# 3. Définir la colonne cible (7C00 Fraud)\n",
    "target = df['7C00 Fraud']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Exporter le modèle Random Forest entraîné\n",
    "joblib.dump(rf_classifier, '7C00_new_model_random_forest.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jklRfNlFIcyj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "rf_classifier_loaded = joblib.load('7C00_new_model_random_forest.pkl')\n",
    "\n",
    "\n",
    "new_df = pd.read_csv('/content/test7c00 - pole (2).csv (3).csv')\n",
    "\n",
    "new_df['7C00Taux 2'] = new_df['7C00Taux 2'].fillna(0)\n",
    "new_df['7C00Base'] = new_df['7C00Base'].fillna(0)\n",
    "\n",
    "\n",
    "features_new = new_df[['7C00Base', '7C00Taux 2']]\n",
    "\n",
    "\n",
    "predictions = rf_classifier_loaded.predict(features_new)\n",
    "\n",
    "\n",
    "new_df['anomalie_predite'] = predictions\n",
    "\n",
    "# Optionnel : Sauvegarder la nouvelle base avec les prédictions\n",
    "# new_df.to_csv('nouvelle_base_avec_predictions.csv', index=False)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQkuUQwsO0lF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNDRgaQcIpPH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj-8NiRgy9FF"
   },
   "source": [
    "# 7C10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcrAZKGjy_7w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"pole.csv\")\n",
    "percentage = 0.20\n",
    "def generer_taux_errone_maladie(eliminer_valeur=None):\n",
    "\n",
    "    taux_errone = round(np.random.uniform(0, 10), 2) \n",
    "    while eliminer_valeur is not None and taux_errone == eliminer_valeur:\n",
    "        taux_errone = round(np.random.uniform(0, 10), 2)  \n",
    "    return taux_errone\n",
    "\n",
    "maladie_rows = df.sample(frac=percentage).index\n",
    "df['7C10 Fraud'] = 0\n",
    "for idx in maladie_rows:\n",
    "    if df.at[idx, '7C10Taux 2'] == 0.0:\n",
    "        df.at[idx, '7C10Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=0.0)\n",
    "        df.at[idx, '7C10 Fraud'] = 1\n",
    "    elif df.at[idx, '7C10Taux 2'] == 4.05:\n",
    "        df.at[idx, '7C10Taux 2'] = generer_taux_errone_maladie(eliminer_valeur=4.05)\n",
    "        df.at[idx, '7C10 Fraud'] = 1\n",
    "    # elif df.at[idx, '7C10Base'] == 0.0:\n",
    "    #     df.at[idx, '7C10Taux 2'] = round(np.random.uniform(1, 10), 2)\n",
    "    #     df.at[idx, '7C10 Fraud'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sauvegarder le DataFrame modifié\n",
    "df.to_csv(\"7C10_avec_anomalies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBmCWel_y_5Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv('7C10_avec_anomalies.csv')\n",
    "\n",
    "features = df[[ 'Type de contrat','7C10Base' ,'7C10Taux 2']]\n",
    "\n",
    "features_encoded = pd.get_dummies(features, columns=['Type de contrat'], drop_first=True)\n",
    "\n",
    "target = df['7C10 Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=110, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Accuracy: {accuracy * 110:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgFo0tI5zDdA"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Exporter le modèle Random Forest entraîné\n",
    "joblib.dump(rf_classifier, '7C10_new_model_random_forest.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDSgHjd0zDab"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "rf_classifier_loaded = joblib.load('7C10_new_model_random_forest.pkl')\n",
    "\n",
    "\n",
    "new_df = pd.read_csv('/content/test7c10 - pole (2).csv (1).csv')\n",
    "df['7C10Taux 2'] = df['7C10Taux 2'].fillna(0)\n",
    "df['7C10Base'] = df['7C10Base'].fillna(0)\n",
    "\n",
    "\n",
    "features_new = new_df[[ 'Type de contrat','7C10Base' ,'7C10Taux 2']]\n",
    "\n",
    "\n",
    "features_new_encoded = pd.get_dummies(features_new, columns=['Type de contrat'], drop_first=True)\n",
    "\n",
    "missing_cols = set(features_encoded.columns) - set(features_new_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    features_new_encoded[c] = 0\n",
    "\n",
    "\n",
    "features_new_encoded = features_new_encoded[features_encoded.columns]\n",
    "\n",
    "\n",
    "predictions = rf_classifier_loaded.predict(features_new_encoded)\n",
    "\n",
    "\n",
    "new_df['anomalie_predite'] = predictions\n",
    "\n",
    "\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxVJ7M1My_2p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UNsY-xYqIcr3"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
